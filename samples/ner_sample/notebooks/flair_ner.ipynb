{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named Entity Recognition using Flair on CONLL-2003\n",
    "## Experiment description\n",
    "This notebook contains a ML fabric flow for Named Entity Recognition\n",
    "using the [flair NLP package](https://github.com/flairNLP/flair/)\n",
    "\n",
    "Note: This example implements all the required data objects. For a clean notebook which uses the objects already implemented in the `ner_sample` Python package [click here](flair_ner_clean.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Jupyter helpers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "import flair\n",
    "import requests\n",
    "import torch\n",
    "from flair.data import Corpus, Sentence\n",
    "from flair.datasets import CONLL_03\n",
    "from flair.embeddings import TokenEmbeddings, WordEmbeddings, StackedEmbeddings, PooledFlairEmbeddings\n",
    "from flair.models import SequenceTagger\n",
    "from flair.trainers import ModelTrainer\n",
    "from seqeval.metrics import f1_score, accuracy_score\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from ner_sample import ExperimentRunner\n",
    "from ner_sample.data import DataLoader\n",
    "from ner_sample.evaluation import Evaluator, EvaluationMetrics\n",
    "from ner_sample.experimentation import MlflowExperimentation\n",
    "from ner_sample.models import BaseModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConllDataLoader(DataLoader):\n",
    "\n",
    "    def __init__(self, dataset_name, dataset_version='1', local_data_path = '../data/processed/'):\n",
    "        self.folds = ('eng.train', 'eng.testa', 'eng.testb')\n",
    "        self.local_data_path = local_data_path\n",
    "        super().__init__(dataset_name=dataset_name, dataset_version=dataset_version)\n",
    "\n",
    "    def download_dataset(self) -> None:\n",
    "        \n",
    "        if self.dataset_name==\"conll_03\" and self.dataset_version == '1':\n",
    "            \n",
    "            for fold in self.folds:\n",
    "                local_path = Path(self.local_data_path,self.dataset_name).resolve()\n",
    "                \n",
    "                if not local_path.exists():\n",
    "                    local_path.mkdir(parents=True)\n",
    "\n",
    "                dataset_file = Path(local_path, fold)\n",
    "                if dataset_file.exists():\n",
    "                    print(\"Dataset already exists, skipping download\")\n",
    "                    return\n",
    "\n",
    "                dataset_path=f\"https://raw.githubusercontent.com/glample/tagger/master/dataset/{fold}\"\n",
    "                response = requests.get(dataset_path)\n",
    "                dataset_raw = response.text\n",
    "                with open(dataset_file, \"w\") as f:\n",
    "                    f.write(dataset_raw)\n",
    "                print(f\"Finished writing fold {fold} to {self.local_data_path}\")\n",
    "\n",
    "            print(f\"Finished downloading dataset {self.dataset_name} version {self.dataset_version}\")\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(\"Selected dataset was not found\")\n",
    "\n",
    "    def get_dataset(self) -> Corpus:\n",
    "        try:\n",
    "            return CONLL_03(base_path=self.local_data_path, in_memory=True)\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Dataset {self.dataset_name} with version {self.dataset_version} not found in data/raw\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "*replace MyDataLoader with your DataLoader implementation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = ConllDataLoader(dataset_name = \"conll_03\")\n",
    "data_loader.download_dataset()\n",
    "corpus = data_loader.get_dataset()\n",
    "corpus=corpus.downsample(0.05) # Just for example purposes\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"First sample in train sample:\\n {corpus.train.dataset[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Define experimentation object, which will be used for logging the experiments parameters, metrics and artifacts\n",
    "*Replace MlflowExperimentation if you use a different experimentation system*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experimentation = MlflowExperimentation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Create model/logic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flair.device = torch.device(\"cpu\")\n",
    "\n",
    "class FlairNERModel(BaseModel):\n",
    "\n",
    "    def __init__(self, \n",
    "                 corpus: Corpus,\n",
    "                 hidden_size: int =256, \n",
    "                 pooling: str = 'min', \n",
    "                 word_embeddings: str='glove',\n",
    "                 train_with_dev: bool = True,\n",
    "                 max_epochs: int = 10):\n",
    "        self.tag_type = 'ner'\n",
    "        self.tag_dictionary = None\n",
    "        self.tagger = None\n",
    "        self.embeddings = None\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.pooling = pooling\n",
    "        self.word_embeddings = word_embeddings\n",
    "        self.train_with_dev = train_with_dev\n",
    "        self.max_epochs = max_epochs\n",
    "        \n",
    "        self.set_tagger_definition(corpus)\n",
    "        \n",
    "        hyper_params = self.get_hyper_params(hidden_size=hidden_size, \n",
    "                             pooling=pooling, \n",
    "                             word_embeddings=word_embeddings, \n",
    "                             train_with_dev=train_with_dev, \n",
    "                             max_epochs=max_epochs)\n",
    "        \n",
    "        super().__init__(**hyper_params)\n",
    "\n",
    "    def get_hyper_params(self, **hyper_params):\n",
    "        basic_params = {param_name: param_value \n",
    "                        for (param_name, param_value) in self.tagger.__dict__.items() \n",
    "                        if type(param_value) in (bool, float, int, str)}\n",
    "        hyper_params.update(basic_params)\n",
    "        return hyper_params\n",
    "        \n",
    "    def set_embeddings_definition(self) -> List[TokenEmbeddings]:\n",
    "        \"\"\"\n",
    "        Sets the embedding layers used by this tagger\n",
    "        \"\"\"\n",
    "        # initialize embeddings\n",
    "        embedding_types: List[TokenEmbeddings] = [\n",
    "\n",
    "        # Word embeddings (default = GloVe)\n",
    "        WordEmbeddings(self.word_embeddings),\n",
    "\n",
    "        # contextual string embeddings, forward\n",
    "        PooledFlairEmbeddings('news-forward', pooling=self.pooling),\n",
    "\n",
    "        # contextual string embeddings, backward\n",
    "        PooledFlairEmbeddings('news-backward', pooling=self.pooling)\n",
    "        ]\n",
    "        self.embeddings: StackedEmbeddings = StackedEmbeddings(embeddings=embedding_types)\n",
    "    \n",
    "    def set_tagger_definition(self, corpus:Corpus) -> SequenceTagger:\n",
    "        \"\"\"\n",
    "        Returns the definition of the Flair SequenceTagger (the full model)\n",
    "        :param corpus: Used only for setting the tag_dictionary\n",
    "        \"\"\"\n",
    "        \n",
    "        if not self.embeddings:\n",
    "            self.set_embeddings_definition()\n",
    "        self.tag_dictionary = corpus.make_tag_dictionary(tag_type=self.tag_type)\n",
    "        \n",
    "        tagger: SequenceTagger = SequenceTagger(hidden_size=self.hidden_size,\n",
    "                                                embeddings=self.embeddings,\n",
    "                                                tag_dictionary=self.tag_dictionary,\n",
    "                                                tag_type=self.tag_type,\n",
    "                                                use_crf=False)\n",
    "        self.tagger = tagger\n",
    "        \n",
    "    def fit(self, corpus: Corpus) -> None:\n",
    "        # initialize trainer\n",
    "        trainer: ModelTrainer = ModelTrainer(self.tagger, corpus)\n",
    "\n",
    "        trainer.train('models/taggers/flair-ner',\n",
    "                      train_with_dev=self.train_with_dev,  \n",
    "                      max_epochs=self.max_epochs)\n",
    "\n",
    "    def predict(self, sentences):\n",
    "        tagged_sentences = []\n",
    "        for sentence in tqdm(sentences):\n",
    "            self.tagger.predict(sentence)\n",
    "            tagged_sentences.append(sentence)\n",
    "        return tagged_sentences\n",
    "            \n",
    "model = FlairNERModel(corpus=corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN=False\n",
    "\n",
    "if TRAIN:\n",
    "    model.fit(corpus)\n",
    "else:\n",
    "    # Simulate training has finished by downloading a pretrained model\n",
    "    model.tagger = SequenceTagger.load('ner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_sentence = Sentence(\"In Penny Lane, there is a barber showing photographs\")\n",
    "\n",
    "model.predict([example_sentence])\n",
    "for token in example_sentence.tokens:\n",
    "    #print(token.__dict__)\n",
    "    print(f\" {token.text} | {token.get_tag('ner')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence in [corpus.test[i] for i in range(5)]:\n",
    "    [token.add_tag_label(\"gold_ner\",token.get_tag(\"ner\")) for token in sentence.tokens]\n",
    "    [token.set_label(\"ner\",value=\"O\") for token in sentence.tokens]\n",
    "#for token in test1:\n",
    "    \n",
    "\n",
    "for token in corpus.test[1]:\n",
    "    print(token.get_tag(\"ner\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence in [corpus.test[i] for i in range(5)]:\n",
    "    [token.add_tag_label(\"gold_ner\",token.get_tag(\"ner\")) for token in sentence.tokens]\n",
    "    [token.set_label(\"ner\",value=\"O\") for token in sentence.tokens]\n",
    "\n",
    "predictions = model.predict(corpus.test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Define evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "class NEREvaluationMetrics:\n",
    "    \"\"\"\n",
    "    This class holds the metrics calculated during the experiment run\n",
    "    \"\"\"\n",
    "    def __init__(self,f1, accuracy):\n",
    "        self.f1 = f1\n",
    "        self.accuracy = accuracy\n",
    "\n",
    "class NEREvaluator(Evaluator):\n",
    "    \"\"\"\n",
    "    This class holds the logic for evaluating a prediction outcome\n",
    "    \"\"\"\n",
    "    def evaluate(self, y_test, predicted_sentences) -> EvaluationMetrics:\n",
    "        golds = []\n",
    "        predicted = []\n",
    "        print(y_test)\n",
    "        print(predicted_sentences)\n",
    "        for sentence in predicted_sentences:\n",
    "\n",
    "            gold_tags = [token.get_tag('gold_ner').value for token in sentence.tokens]\n",
    "            golds.append(gold_tags)\n",
    "            predicted_tags = [token.get_tag('ner').value for token in sentence.tokens]\n",
    "            predicted.append(predicted_tags)\n",
    "        \n",
    "        f1 = f1_score(golds, predicted)\n",
    "        accuracy = accuracy_score(golds, predicted)\n",
    "        return NEREvaluationMetrics(f1=f1,accuracy=accuracy)\n",
    "        \n",
    "evaluator = NEREvaluator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define experiment runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NERExperimentRunner(ExperimentRunner):\n",
    "    \n",
    "    def __init__(self,\n",
    "                model,\n",
    "                corpus,\n",
    "                data_loader,\n",
    "                log_experiment,\n",
    "                experiment_logger,\n",
    "                evaluator,\n",
    "                experiment_name):\n",
    "        self.corpus = corpus\n",
    "        super().__init__(model=model,\n",
    "                         data_loader=data_loader, \n",
    "                         log_experiment=log_experiment,\n",
    "                         experiment_logger=experiment_logger,\n",
    "                         evaluator=evaluator, \n",
    "                         experiment_name=experiment_name,\n",
    "                         X_train=None, X_test=None)\n",
    "    \n",
    "    def predict(self):\n",
    "        \"\"\"\n",
    "        Overwriting the ExperimentRunner predict to verify that tags are marked correctly before prediction\n",
    "        \"\"\"\n",
    "        corpus = self.corpus\n",
    "        # Copy gold NER to new label and assign O to all ner labels (to be populated during inference)\n",
    "        for sentence in corpus.test:\n",
    "            [token.add_tag_label(\"gold_ner\",token.get_tag(\"ner\")) for token in sentence.tokens]\n",
    "            [token.set_label(\"ner\",value=\"O\") for token in sentence.tokens]\n",
    "\n",
    "        self._predictions = self.model.predict(corpus.test)\n",
    "\n",
    "\n",
    "experiment_runner = NERExperimentRunner(\n",
    "    model=model,\n",
    "    corpus=corpus,\n",
    "    data_loader=data_loader,\n",
    "    log_experiment=True,\n",
    "    experiment_logger=experimentation,\n",
    "    evaluator=evaluator,\n",
    "    experiment_name=\"Experiment\",\n",
    ")\n",
    "\n",
    "results = experiment_runner.evaluate()\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('ner_sample': conda)",
   "language": "python",
   "name": "python37664bitnersampleconda9d5f3ecca728487ca0fbc34bec2b6e6f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}